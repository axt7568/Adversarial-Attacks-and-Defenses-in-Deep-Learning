# Adversarial-Attacks-and-Defenses-in-Deep-Learning
â€¢ Implemented Adversarial Attacks(FGSM &amp; PGD) on a CNN model limiting its accuracy on the MNIST data from 97% to 49%. Adversarial training was then used to defend against these attacks thereby improving the accuracy from 49% to 92%.
